# -*- coding: utf-8 -*-
"""ejecicioEquipo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GBWAmusHtobgjJJVJRSGDWCKczmNU4qy
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split

# --- 1. SIMULACIÓN DEL DATASET ---

# Generamos 10,000 muestras aleatorias para simular la recolección de datos
N_SAMPLES = 10000
X = np.random.rand(N_SAMPLES, 8)

# Generamos etiquetas simuladas (0=Seguro, 1=Trampa, 2=Tesoro)
# Creamos una lógica "fake" para que la red tenga algo que aprender:
# Si hay mucha Brisa (feature 0 > 0.8), alta probabilidad de Trampa (1)
y = np.zeros(N_SAMPLES)
for i in range(N_SAMPLES):
    if X[i, 0] > 0.8: # Mucha brisa
        y[i] = 1 # Trampa
    elif X[i, 1] > 0.8: # Mucho destello
        y[i] = 2 # Tesoro
    else:
        y[i] = 0 # Seguro

y = tf.keras.utils.to_categorical(y, num_classes=3)

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# --- 2. ARQUITECTURA DE LA RED ---
# MLP Profundo diseñado para contexto local
model = models.Sequential([
    # Capa 1: Representación inicial
    layers.Dense(64, activation='relu', input_shape=(8,)),

    # Capa 2: Captura combinaciones complejas
    layers.Dense(128, activation='relu'),

    # Dropout para evitar sobreajuste
    layers.Dropout(0.2),

    # Capa 3: Refinamiento
    layers.Dense(64, activation='relu'),

    # Salida: Probabilidad para las 3 clases (Seguro, Trampa, Tesoro)
    layers.Dense(3, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy', tf.keras.metrics.Recall(name='recall')])

# --- 3. ENTRENAMIENTO ---
print("Entrenando Cerebro del Robot...")
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)
print("Entrenamiento finalizado.")

import matplotlib.pyplot as plt

# Obtener los datos del historial de entrenamiento
accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(accuracy) + 1)

# Gráfica de Precisión (Accuracy)
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, accuracy, 'bo-', label='Precisión de Entrenamiento')
plt.plot(epochs, val_accuracy, 'ro-', label='Precisión de Validación')
plt.title('Precisión de Entrenamiento y Validación')
plt.xlabel('Época')
plt.ylabel('Precisión')
plt.legend()
plt.grid(True)

# Gráfica de Pérdida (Loss)
plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'bo-', label='Pérdida de Entrenamiento')
plt.plot(epochs, val_loss, 'ro-', label='Pérdida de Validación')
plt.title('Pérdida de Entrenamiento y Validación')
plt.xlabel('Época')
plt.ylabel('Pérdida')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

class CerebroNavegacion:
    def __init__(self, modelo_entrenado):
        self.nn = modelo_entrenado
        self.PENALIZACION_MUERTE = 1000.0  # Costo altísimo si es trampa
        self.last_prediction = None # Para almacenar la última predicción de la NN

    def obtener_costo_neuro_simbolico(self, perceptos_actuales, reglas_logicas):

        # 1. PREPROCESAMIENTO
        # Convertimos los sensores del robot al formato que espera la red
        vector_entrada = np.array([perceptos_actuales]).reshape(1, 8)

        # 2. INFERENCIA NEURONAL (Intuición)
        # La red nos da: [Prob_Seguro, Prob_Trampa, Prob_Tesoro]
        prediccion = self.nn.predict(vector_entrada, verbose=0)[0]
        self.last_prediction = prediccion # Almacenamos la predicción para visualización
        prob_trampa = prediccion[1]
        prob_tesoro = prediccion[2]

        # 3. FILTRO LÓGICO (Reglas duras - Wumpus Logic)
        # Si la lógica deduce que es seguro (ej. visitado antes), ignoramos el miedo de la NN
        if reglas_logicas['es_seguro_confirmado']:
            prob_trampa = 0.0

        # Si la lógica deduce trampa segura, la probabilidad es 100%
        if reglas_logicas['trampa_detectada']:
            prob_trampa = 1.0

        # 4. CÁLCULO DE COSTO HÍBRIDO (Para A*)
        # Costo base de movimiento = 1
        # Penalización = Probabilidad de muerte * Costo de morir
        # Incentivo = Probabilidad de tesoro (reducimos el costo para atraer al robot)

        costo_total = 1.0 + (prob_trampa * self.PENALIZACION_MUERTE) - (prob_tesoro * 50.0)

        return max(1.0, costo_total) # El costo nunca puede ser menor a 1


cerebro = CerebroNavegacion(model)


perceptos_celda_frontera = [0.9, 0.1, 0.0, 0, 0, 0, 0, 5]
reglas_conocidas = {'es_seguro_confirmado': False, 'trampa_detectada': False}

costo = cerebro.obtener_costo_neuro_simbolico(perceptos_celda_frontera, reglas_conocidas)

print(f"\n--- Decisión del Agente ---")
print(f"Percepción: Brisa fuerte detectada.")
print(f"Costo calculado para A*: {costo:.2f}")

if costo > 500:
    print("ACCIÓN: Celda demasiado peligrosa. El A* buscará otro camino.")
else:
    print("ACCIÓN: Riesgo aceptable. Explorando.")

import matplotlib.pyplot as plt

# --- Función para visualizar una predicción completa ---
def visualizar_decision_agente(cerebro_navegacion, perceptos, reglas_logicas):
    costo_calculado = cerebro_navegacion.obtener_costo_neuro_simbolico(perceptos, reglas_logicas)
    prediccion_nn = cerebro_navegacion.last_prediction

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # 1. Visualización de Perceptos de Entrada
    axes[0].barh([f'Feature {i}' for i in range(len(perceptos))], perceptos, color='skyblue')
    axes[0].set_title('Perceptos de Entrada del Robot')
    axes[0].set_xlabel('Valor del Percepto')
    axes[0].set_xlim(0, 1) # Asumiendo que los perceptos están normalizados entre 0 y 1
    axes[0].grid(axis='x', linestyle='--')

    # 2. Visualización de Probabilidades de la Red Neuronal
    clases = ['Seguro', 'Trampa', 'Tesoro']
    colores = ['lightgreen', 'salmon', 'gold']
    axes[1].bar(clases, prediccion_nn, color=colores)
    axes[1].set_title('Probabilidades de la Red Neuronal')
    axes[1].set_ylabel('Probabilidad')
    axes[1].set_ylim(0, 1)
    axes[1].grid(axis='y', linestyle='--')

    plt.suptitle(f'Decisión del Agente (Costo Neuro-Simbólico: {costo_calculado:.2f})', fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

    print(f"\n--- Análisis de Decisión ---")
    print(f"Perceptos de entrada: {perceptos}")
    print(f"Probabilidades NN (Seguro, Trampa, Tesoro): {prediccion_nn}")
    print(f"Reglas lógicas aplicadas: {reglas_logicas}")
    print(f"Costo final calculado para A*: {costo_calculado:.2f}")
    if costo_calculado > 500:
        print("ACCIÓN SUGERIDA: Celda demasiado peligrosa. Evitar.")
    elif costo_calculado < 0:
        print("ACCIÓN SUGERIDA: Celda altamente atractiva (Tesoro). Priorizar.")
    else:
        print("ACCIÓN SUGERIDA: Riesgo aceptable o neutral. Explorar si es necesario.")


# --- EJEMPLO 1: Brisa fuerte (Trampa probable) ---
print("\n--- Escenario 1: Brisa fuerte ---")
perceptos_escenario1 = [0.9, 0.1, 0.0, 0, 0, 0, 0, 0.5]
reglas_escenario1 = {'es_seguro_confirmado': False, 'trampa_detectada': False}
visualizar_decision_agente(cerebro, perceptos_escenario1, reglas_escenario1)

# --- EJEMPLO 2: Destello fuerte (Tesoro probable) ---
print("\n--- Escenario 2: Destello fuerte ---")
perceptos_escenario2 = [0.1, 0.9, 0.0, 0, 0, 0, 0, 0.5]
reglas_escenario2 = {'es_seguro_confirmado': False, 'trampa_detectada': False}
visualizar_decision_agente(cerebro, perceptos_escenario2, reglas_escenario2)

# --- EJEMPLO 3: Sin peligro aparente ---
print("\n--- Escenario 3: Celda segura (por NN) ---")
perceptos_escenario3 = [0.1, 0.1, 0.2, 0, 0, 0, 0, 0.5]
reglas_escenario3 = {'es_seguro_confirmado': False, 'trampa_detectada': False}
visualizar_decision_agente(cerebro, perceptos_escenario3, reglas_escenario3)

# --- EJEMPLO 4: Lógica de 'seguro confirmado' sobreescribe NN (aunque haya algo de brisa) ---
print("\n--- Escenario 4: Seguro confirmado por lógica ---")
perceptos_escenario4 = [0.7, 0.1, 0.0, 0, 0, 0, 0, 0.5] # Algo de brisa, pero...
reglas_escenario4 = {'es_seguro_confirmado': True, 'trampa_detectada': False}
visualizar_decision_agente(cerebro, perceptos_escenario4, reglas_escenario4)

# --- EJEMPLO 5: Lógica de 'trampa detectada' sobreescribe NN ---
print("\n--- Escenario 5: Trampa confirmada por lógica ---")
perceptos_escenario5 = [0.1, 0.1, 0.0, 0, 0, 0, 0, 0.5] # NN diría seguro, pero...
reglas_escenario5 = {'es_seguro_confirmado': False, 'trampa_detectada': True}
visualizar_decision_agente(cerebro, perceptos_escenario5, reglas_escenario5)

y_pred_proba = model.predict(X_test)
y_pred_labels = np.argmax(y_pred_proba, axis=1)

print("Probabilidades de las primeras 5 predicciones:\n", y_pred_proba[:5])
print("Etiquetas predichas para las primeras 5 muestras:\n", y_pred_labels[:5])

y_true_labels = np.argmax(y_test, axis=1)

print("Etiquetas verdaderas para las primeras 5 muestras:\n", y_true_labels[:5])

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Calcular la matriz de confusión
cm = confusion_matrix(y_true_labels, y_pred_labels)

# Definir los nombres de las clases
class_names = ['Seguro', 'Trampa', 'Tesoro']

# Visualizar la matriz de confusión
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Etiqueta Predicha')
plt.ylabel('Etiqueta Verdadera')
plt.title('Matriz de Confusión')
plt.show()